"""
Kaggle Dataset Loader for Trip Planner ML
Downloads and loads travel-related datasets from Kaggle
"""

import os
import pandas as pd
from pathlib import Path
import kaggle
from typing import Dict, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class KaggleDataLoader:
    """
    Loads travel and tourism datasets from Kaggle for ML training
    """
    
    def __init__(self, data_dir: str = "data/raw"):
        """
        Initialize the Kaggle data loader
        
        Args:
            data_dir: Directory to store downloaded datasets
        """
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Dataset configurations - ALL PUBLIC & VERIFIED WORKING
        self.datasets = {
            'destinations': 'rkiattisak/traveler-trip-data',         # ‚úÖ Traveler destinations
            'hotels': 'keshavramaiah/hotel-recommendation',          # ‚úÖ Already working
            'attractions': 'flashgordon/usa-airport-dataset',        # ‚úÖ Already working  
            'budget': 'leomauro/argodatathon2019',                   # ‚úÖ Travel expenses
        }
        
    def download_dataset(self, dataset_name: str, force_download: bool = False) -> Path:
        """
        Download a specific dataset from Kaggle
        
        Args:
            dataset_name: Name of the dataset to download
            force_download: Force re-download even if exists
            
        Returns:
            Path to the downloaded dataset directory
        """
        if dataset_name not in self.datasets:
            raise ValueError(f"Unknown dataset: {dataset_name}")
            
        dataset_path = self.data_dir / dataset_name
        
        # Check if already downloaded
        if dataset_path.exists() and not force_download:
            logger.info(f"Dataset '{dataset_name}' already exists at {dataset_path}")
            return dataset_path
            
        # Download using Kaggle API
        try:
            dataset_slug = self.datasets[dataset_name]
            logger.info(f"Downloading {dataset_name} from Kaggle: {dataset_slug}")
            
            kaggle.api.dataset_download_files(
                dataset_slug,
                path=dataset_path,
                unzip=True
            )
            
            logger.info(f"Successfully downloaded {dataset_name}")
            return dataset_path
            
        except Exception as e:
            logger.error(f"Error downloading {dataset_name}: {str(e)}")
            logger.error("Make sure you have configured Kaggle API credentials")
            logger.error("See: https://www.kaggle.com/docs/api")
            raise
    
    def _load_csv_from_path(self, dataset_path: Path, dataset_name: str) -> pd.DataFrame:
        """
        Helper method to load CSV from dataset path
        
        Args:
            dataset_path: Path to dataset directory
            dataset_name: Name of dataset for logging
            
        Returns:
            DataFrame with the loaded data
        """
        csv_files = list(dataset_path.glob("*.csv"))
        
        if not csv_files:
            raise FileNotFoundError(f"No CSV files found in {dataset_path}")
        
        # Sort by file size (largest first) to get main dataset
        csv_files_sorted = sorted(csv_files, key=lambda x: x.stat().st_size, reverse=True)
        
        # Try loading files until one works
        for csv_file in csv_files_sorted:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8')
                logger.info(f"Loaded {dataset_name} from {csv_file.name}: {len(df)} records")
                return df
            except Exception as e:
                logger.warning(f"Failed to load {csv_file.name}: {e}")
                continue
        
        raise ValueError(f"Could not load any CSV files from {dataset_path}")
            
    def load_destinations_data(self) -> pd.DataFrame:
        """
        Load travel destinations and trip data
        
        Returns:
            DataFrame with destinations and trip information
        """
        dataset_path = self.download_dataset('destinations')
        return self._load_csv_from_path(dataset_path, 'destinations')
        
    def load_hotel_data(self) -> pd.DataFrame:
        """
        Load hotel booking and recommendation data
        
        Returns:
            DataFrame with hotel information
        """
        dataset_path = self.download_dataset('hotels')
        return self._load_csv_from_path(dataset_path, 'hotels')
        
    def load_attractions_data(self) -> pd.DataFrame:
        """
        Load attractions and points of interest data
        
        Returns:
            DataFrame with attractions information
        """
        dataset_path = self.download_dataset('attractions')
        return self._load_csv_from_path(dataset_path, 'attractions')
        
    def load_budget_data(self) -> pd.DataFrame:
        """
        Load travel budget and expense data
        
        Returns:
            DataFrame with budget information
        """
        dataset_path = self.download_dataset('budget')
        return self._load_csv_from_path(dataset_path, 'budget')
        
    def load_all_datasets(self) -> Dict[str, pd.DataFrame]:
        """
        Load all available datasets
        
        Returns:
            Dictionary mapping dataset names to DataFrames
        """
        logger.info("Loading all datasets...")
        
        datasets = {}
        errors = []
        
        # Try loading each dataset
        loaders = {
            'destinations': self.load_destinations_data,
            'hotels': self.load_hotel_data,
            'attractions': self.load_attractions_data,
            'budget': self.load_budget_data
        }
        
        for name, loader_func in loaders.items():
            try:
                datasets[name] = loader_func()
                logger.info(f"‚úì Successfully loaded {name}")
            except Exception as e:
                error_msg = f"‚úó Could not load {name}: {str(e)}"
                logger.error(error_msg)
                errors.append(error_msg)
        
        # Summary
        logger.info(f"\n{'='*60}")
        logger.info(f"Successfully loaded {len(datasets)}/{len(loaders)} datasets")
        
        if errors:
            logger.warning(f"\nFailed to load {len(errors)} datasets:")
            for error in errors:
                logger.warning(f"  {error}")
        
        if not datasets:
            logger.warning("\nNo datasets loaded successfully. Creating synthetic data...")
            return self.create_synthetic_data()
            
        return datasets
        
    def create_synthetic_data(self) -> Dict[str, pd.DataFrame]:
        """
        Create synthetic training data if Kaggle data is not available
        
        Returns:
            Dictionary with synthetic datasets
        """
        import numpy as np
        
        logger.info("Creating synthetic training data...")
        
        # Synthetic places data
        n_places = 1000
        places_df = pd.DataFrame({
            'place_id': range(n_places),
            'name': [f'Place_{i}' for i in range(n_places)],
            'city': np.random.choice(['Paris', 'Tokyo', 'New York', 'London', 'Rome'], n_places),
            'country': np.random.choice(['France', 'Japan', 'USA', 'UK', 'Italy'], n_places),
            'category': np.random.choice(['attraction', 'restaurant', 'hotel', 'museum', 'park'], n_places),
            'rating': np.random.uniform(3.0, 5.0, n_places),
            'num_reviews': np.random.randint(10, 5000, n_places),
            'price_level': np.random.randint(1, 5, n_places),
            'latitude': np.random.uniform(-90, 90, n_places),
            'longitude': np.random.uniform(-180, 180, n_places)
        })
        
        # Synthetic user interactions
        n_interactions = 5000
        interactions_df = pd.DataFrame({
            'user_id': np.random.randint(0, 500, n_interactions),
            'place_id': np.random.randint(0, n_places, n_interactions),
            'rating': np.random.uniform(1.0, 5.0, n_interactions),
            'visited': np.random.choice([0, 1], n_interactions),
            'liked': np.random.choice([0, 1], n_interactions)
        })
        
        # Synthetic trip budgets
        n_trips = 2000
        trips_df = pd.DataFrame({
            'trip_id': range(n_trips),
            'destination': np.random.choice(['Paris', 'Tokyo', 'New York', 'London', 'Rome'], n_trips),
            'num_days': np.random.randint(3, 14, n_trips),
            'num_people': np.random.randint(1, 6, n_trips),
            'accommodation_level': np.random.randint(1, 5, n_trips),
            'total_budget': np.random.uniform(500, 5000, n_trips),
            'travel_style': np.random.choice(['budget', 'moderate', 'luxury'], n_trips)
        })
        
        logger.info(f"Created synthetic data: {len(places_df)} places, {len(interactions_df)} interactions, {len(trips_df)} trips")
        
        return {
            'places': places_df,
            'interactions': interactions_df,
            'trips': trips_df
        }
    
    def get_dataset_info(self) -> Dict[str, str]:
        """
        Get information about configured datasets
        
        Returns:
            Dictionary with dataset names and their Kaggle slugs
        """
        return self.datasets.copy()


if __name__ == "__main__":
    # Test the loader
    loader = KaggleDataLoader()
    
    print("\n" + "="*60)
    print("KAGGLE DATASET LOADER TEST")
    print("="*60)
    
    print("\nConfigured datasets:")
    for name, slug in loader.get_dataset_info().items():
        print(f"  ‚Ä¢ {name}: {slug}")
    
    print("\n" + "="*60)
    print("LOADING DATASETS...")
    print("="*60 + "\n")
    
    try:
        # Try to load real data
        datasets = loader.load_all_datasets()
        
        if datasets:
            print("\n" + "="*60)
            print("DATASET SUMMARY")
            print("="*60)
            
            for name, df in datasets.items():
                print(f"\nüìä {name.upper()}")
                print(f"  Shape: {df.shape}")
                print(f"  Columns: {list(df.columns)[:5]}")  # Show first 5 columns
                if len(df.columns) > 5:
                    print(f"           ... and {len(df.columns) - 5} more")
                print(f"  Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        else:
            print("\n‚ö†Ô∏è  No datasets loaded successfully")
            
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        print("\nTip: Make sure you have:")
        print("  1. Installed kaggle: pip install kaggle")
        print("  2. Set up API credentials in ~/.kaggle/kaggle.json")
        print("  3. Internet connection")
    
    print("\n" + "="*60)